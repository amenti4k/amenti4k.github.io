---
layout: post
title: "Load-Bearing Nothing"
date: 2026-02-08
tags: [business, ai]
---

- In structural engineering there's a thing called parasitic load. The weight of a building that only exists to support the building itself. Beams holding up beams. Floors that exist so you can put columns on them to hold up other floors. In a good structure it's maybe fifteen percent. In a bad one the building is mostly just holding itself up.

- Nobody designs it that way on purpose. It accretes. Steel bends, concrete cracks, gravity doesn't negotiate. The engineers who built those beams weren't stupid. They were solving real problems with what they had.

- For a long time that's how I understood the white collar economy. Approvals that exist to authorize other approvals. Reconciliations that reconcile reconciliations. Coordination layers whose entire job is managing the complexity that coordination layers created. It looked parasitic but it felt necessary, because no one person could hold the full picture in their head. We needed the handoffs. We needed the sign-offs. Cognition has a carrying capacity and the work outgrew it.

- We built entire industries around this. SaaS to manage the load. Consultancies to audit it. MBA programs to teach people to sit on top of it with the quiet confidence of someone who's never asked whether the beams are actually holding anything up.

- The conventional wisdom was that the complexity was structural. Cost of doing business. Weight of the building.

- It isn't.

- I've built the proof. Orchestration layers, autonomous agents, the stuff that gets breathless LinkedIn posts written about it. First time I watched one consume an entire workflow I expected it to just do the work faster. Approval chains, exception handling for exception handling, a shared spreadsheet that three people understood and two of them had quit. The agent didn't do it faster. It skipped most of it. Not cutting corners. The corners just didn't need to exist.

- The reconciliations were reconciling discrepancies the handoffs created. The approvals were authorizing work that only needed authorizing because it had been split across people who couldn't see each other's context. The load wasn't supporting the operation. It was supporting the fact that humans were running the operation.

- Remove the cognitive bottleneck and the load-bearing walls turn out to be vestigial.

- I used to think the craft in AI was building around the model. Scaffolding, retrieval systems, the careful engineering that makes something actually work in production. I spent years getting good at it. Then I watched every system I built get swallowed by the next model. Not metaphorically. Every workaround, every clever pipeline. Gone. The only thing that survived was what I knew about the domain, the failure modes, the edge cases, the texture of what "good" means in a specific context. Most AI engineering is building depreciating assets and calling it craft. The thing that compounds is the problem definition itself.

- Second time I watched it happen, different industry, same thing, faster. I'd already learned which walls were decorative. Third time, faster still.

- Here's what gets applauded at AI conferences and ignored in the parking lot: the value doesn't go to whoever sells the tool. The tool is commodity. Some other team running the same model with a different pitch deck undercuts you by Wednesday. The value goes to whoever owns the operation underneath. Vendor captures a licensing fee. Owner captures everything the building was wasting on itself.

- And the weight is enormous. Operations running on margins that would embarrass a lemonade stand. Not because the businesses are bad but because they've been spending most of their energy holding themselves up.

- What makes this more than a cost-cutting story is what happens when you do it across multiple operations and the learning starts to compound. Each one teaches you why operations carry unnecessary weight. The patterns rhyme. The failure modes repeat. Second building is easier than the first. Tenth is dramatically easier than the third.

- When intelligence flows between structures, when every decorative wall you find in one teaches you to spot the next one faster, what you're building isn't a portfolio or a holding company. It's a learning system. The value isn't the buildings. It's the relationship between them. The accumulated understanding of which loads are real and which ones we invented.

- But there's a wall it hits and I've watched smart people pretend it's not there. Someone still has to sit across from a board member furious about a landscaping bill who will never care that an algorithm optimized the vendor selection. Someone has to sign the thing, hold the liability, absorb the specific species of anger that has nothing to do with outcomes and everything to do with not feeling heard by a person.

- The system can handle the problem. It cannot handle the person who has the problem.

- What persists is a thin human layer of trust. Not because the system needs it but because people need to believe someone with a pulse is accountable. Intelligence does the work. Humans provide the surface area for being sued.

- Underneath that the compounding continues. Quiet, structural, in industry after industry priced for an era where the load was the business.

- I keep thinking about the engineers who designed the original beams though. They weren't wrong. They solved real problems and they were genuinely good at it. The problem just stopped being real. And their expertise, hard-won and legitimate, is still sitting there. Load-bearing nothing.
